---
title: 'w271 Lab 2: Cereal Shelf Placement '
author: "Jessica Hays Fisher, Alice Lam, Marshall Ratliff, Paul Varjan"
date: "6/3/2018"
output:
  pdf_document:
    latex_engine: lualatex
    toc: yes
  html_document: default
geometry: margin=1in
fontsize: 11pt
linespace: single
---

```{r}

#Load libraries and insert a function to tidy up the code when they are printed out
library(vcd)
library(nnet)
library(car)
library(Hmisc)
library(skimr)
library(MASS)

rm(list = ls())
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

```

```{r}
cereal <- read.csv("cereal_dillons.csv")
str(cereal)
```

```{r}
# Examine the data to check data validity before proceeding with the questions.
skim(cereal)
```

There are 7 variables with 40 observations evenly distributed across 4 shelves. There's no missing data. There are 38 types of cereal, with sugar content ranging 0 to 20 gram, fat content ranging from 0 to 5 gram, sodium content from 0 to 330 gram, serving size ranging 27 to 60 gram.

*Additional Notes: add scatterplotmatrix for explanatory vars.
```{r, message=F}
#suppress warnings
oldw <- getOption("warn")
options(warn = -1)
scatterplotMatrix(~ size_g + sugar_g + fat_g + sodium_mg, data = cereal)
#restore old warning level
options(warn = oldw)
```

##(a) The explanatory variables need to be re-formatted before proceeding further. First, divide each explanatory variable by its serving size to account for the different serving sizes among the cereals. Second, re-scale each variable to be within 0 and 1. 

```{r}
# the formula is from textbook
standardize <- function(x) { (x - min(x)) / (max(x) - min(x))}
cereal2 <- data.frame(Shelf = cereal$Shelf, Cereal = cereal$Cereal, 
                      sugar = standardize(cereal$sugar_g / cereal$size_g), 
                      fat = standardize(cereal$fat_g / cereal$size_g), 
                      sodium = standardize(cereal$sodium / cereal$size_g))

head(cereal2)
```

##(b) Construct side-by-side box plots with dot plots overlaid for each of the explanatory variables. Also, construct a parallel coordinates plot for the explanatory variables and the shelf number. Discuss if possible content differences exist among the shelves.

```{r}
# this code is from textbook
boxplot(formula = sugar ~ Shelf, data = cereal2, ylab = "Sugar", 
        xlab = "Shelf", main = "Sugar by Shelf", pars = list(outpch=NA))
stripchart(x = cereal2$sugar ~ cereal2$Shelf, lwd = 2, col = "red", 
           method = "jitter", vertical = TRUE, pch = 1, add = TRUE)

boxplot(formula = fat ~ Shelf, data = cereal2, ylab = "Fat", 
        xlab = "Shelf", main = "Fat by Shelf",pars = list(outpch=NA))
stripchart(x = cereal2$fat ~ cereal2$Shelf, lwd = 2, col = "red", 
           method = "jitter", vertical = TRUE, pch = 1, add = TRUE)

boxplot(formula = sodium ~ Shelf, data = cereal2, ylab = "Sodium", 
        xlab = "Shelf", main = "Sodium by Shelf", pars = list(outpch=NA))
stripchart(x = cereal2$sodium ~ cereal2$Shelf, lwd = 2, col = "red", 
           method = "jitter", vertical = TRUE, pch = 1, add = TRUE)

```

```{r}
cereal3<-data.frame(cereal2[1], cereal2[3], cereal2[5], cereal2[4])

# Colors by condition:
cereal.colors<-ifelse(test = cereal2$Shelf==1, yes = "cornsilk4", 
                no = ifelse(test = cereal2$Shelf==2, yes = "coral2", 
                no = ifelse(test = cereal2$Shelf==3, yes = "blueviolet", no= "aquamarine3")))
# Line type by condition:
cereal.lty<-ifelse(test = cereal2$Shelf==1, yes = "solid", 
                no = ifelse(test = cereal2$Shelf==2, yes = "twodash", 
                no = ifelse(test = cereal2$Shelf==3, yes = "solid", no = "twodash")))

parcoord(x = cereal3, col = cereal.colors, lty = cereal.lty)  # Plot
legend(x = 3.35, y = 1.05, legend = c("Shelf 1", "Shelf 2", "Shelf 3", "Shelf 4"), lty = c("solid", "twodash", "solid", "twodash"),
  col=c("cornsilk4", "coral2", "blueviolet","aquamarine3"), cex=0.8, bty="n")
```

High sugar content seems to be most prevalent among Shelf 2. The other shelves have a pretty wide spread of sugar content, with means roughly in the same places. Of note is Shelf 1's bimodal distribution of sugar, with one cluster of cereals with nearly no sugar and the other cluster having above average sugar content. Without that low sugar cluster, the rest of the shelf would have a mean sugar content much closer to Shelf 2.

Fat content seems to be pretty evenly distributed across shelves. In cereal this most likely corresponds to contents like nuts and oilseeds. There is a heavy occurrence of fat content at both extremes (1 and 0). Shelf 1 has so many 0 fat score cereals that its mean is lower than the others. Perhaps also notable is that shelf 2 is the only shelf with no cereals with a 0 score for fat, and that shelf 4 is the only shelf with no cereals with a 1 score, but visually, that information does not add muchin light of the rest of the fat content plots.

Sodium content is notably highest on Shelf 1, but otherwise the other shelves have a more or less similar mean, with Shelf 3 showing the most breadth of sodium levels within that shelf. 

*Additional Notes: The cereals with lowest sugar content on shelf 2 had elevated fat and sodium content comparatively, indicating there is still an inflated flavor profile corresponding to likely less healthy but popular cereals. **Check that reordering matches our analysis*

##(c) The response has values of 1, 2, 3, and 4. Under what setting would it be desirable to take into account ordinality. Do you think this occurs here?

Answer: If we believed that there was a natural ordering to the shelves, or that they could be arranged in an order such that shelf 1 < shelf 2 < shelf 3, etc. - then we would be desirable to take into account ordinality (especially if we believed that the "distance" between each level were equal). However, we do not believe that is the case with this data, as it is not clear whether being on a low shelf is objectively better than on a high shelf, or vice versa. There are attractors/detractors from each shelf height and for different customers - for example, children are at the height of lower shelves than adults are - but that ordering is not universal and therefore not desireable to take into account in our modeling.  If other data could be brought in that demonstrated the desirability or marketability of each shelf had some order (which probably does exist), that could also be used as a factor for ordinality.

*Additional Notes: The most significant factors are target audience and some metric of difficulty/ease of reaching a given shelf. If we had stats on shelf heights and arm lengths of target customer groups it may be possible to rank the shelves in a meaningful way. It seems likely that shelves 2 or 3 is highest priority for most products, however given the sensitivity to children for this product segment clearly shelf 2 is highest priority, shelf 4 is lowest, and it is probably difficult to distinguish shelves 1 and 3 but perhaps 1 continues to cater more toward children and 3 more toward adults. In any case, there is still no immediately apparent ordinality aside from a clear distinction between shelf 2 and shelf 4.

##(d) Estimate a multinomial regression model with linear forms of the sugar, fat, and sodium variables. Perform LRTs to examine the importance of each explanatory variable.

```{r}
levels(as.factor(cereal2$Shelf))
mod1 <- multinom(as.factor(Shelf) ~ sugar + fat + sodium, data=cereal2)
summary(mod1)
Anova(mod1)
```

* We cannot use mcprofile package for likelihood ratio, as nnet package author does not believe that one at a time intervals should be calculated. We use value of c equal to 1 standard deviation instead. *

*Additional note: Sugar and Sodium are key discriminating factors both in terms of Log Likelihood and Significance.

##(e) Show that there are no significant interactions among the explanatory variables (including an interaction among all three variables).

```{r}
## Create expanded models including interaction terms between all pairs of explanatory variables and triple interaction between all 3.

modA <- multinom(as.factor(Shelf) ~ sugar + fat + sodium + sugar:fat, data = cereal2)
Anova(modA)

modB <- multinom(as.factor(Shelf) ~ sugar + fat + sodium + sugar:sodium, data = cereal2)
Anova(modB)

modC <- multinom(as.factor(Shelf) ~ sugar + fat + sodium + fat:sodium, data = cereal2)
Anova(modC)

modD <- multinom(as.factor(Shelf) ~ sugar + fat + sodium + fat:sodium:sugar, data = cereal2)
Anova(modD)

modE <- multinom(as.factor(Shelf) ~ sugar + fat + sodium + sugar:fat +
                   sugar:sodium + fat:sodium + fat:sodium:sugar, data = cereal2)
Anova(modE)
```

Looking at the significance values of the likelihood ratio tests for each additional interaction term none of them are even marginally significant, and the individual term significances remain fairly stable in significance levels.

##(f) Kellogg's Apple Jacks (http://www.applejacks.com) is a cereal marketed toward children. For a serving size of 28 grams, its sugar content is 12 grams, fat content is 0.5 grams, and sodium content is 130 milligrams. Estimate the shelf probabilities for Apple Jacks.

```{r}
stand.new <- function(meas, serv_size, comparison) {( meas/serv_size - min(comparison)) / (max(comparison) - min(comparison))}

newdata <- data.frame(sugar = stand.new(12, 28, cereal$sugar_g/cereal$size_g), 
                      fat = stand.new(0.5, 28, cereal$fat_g/cereal$size_g),
                      sodium = stand.new(130, 28, cereal$sodium_mg/cereal$size_g))

round(predict(object = mod1, newdata = newdata, type = "probs", se.fit = TRUE),7)
```

From the above prediction, we see that Kellogg's Apple Jacks are most likely to be placed on shelf 2, given a relatively elevated level of sugar and a sodium level that falls in the first quantile making shelf 1 fairly unlikely. While it fits squarely in the range of sugary cereals, it does not have an extreme sugar level, so shelves 3 & 4 are still somewhat possible.

##(g) Construct a plot similar to Figure 3.3 where the estimated probability for a shelf is on the y-axis and the sugar content is on the x-axis. Use the mean overall fat and sodium content as the corresponding variable values in the model. Interpret the plot with respect to sugar content.

Alice's solution:

```{r}
newfat <- c(rep(mean(cereal2$fat),11))
newsodium <- c(rep(mean(cereal2$sodium),11))
newsugar <- c(seq(0,1, 0.1))
simulated.data <- data.frame(sugar=newsugar, fat=newfat, sodium=newsodium)
pi.hat.sim <-predict(mod1, newdata=simulated.data, type="probs")
plot.new()
x<- seq(0,1,0.1)
plot(x,pi.hat.sim[,1],type='l',col="blue",
     ylim=range(min(pi.hat.sim), max(pi.hat.sim)),
     xlab = "Sugar", ylab = "predicted probability")
lines(x, pi.hat.sim[,2], col="gray")
lines(x, pi.hat.sim[,3], col="red")
lines(x, pi.hat.sim[,4], col="green")

legend(x = 0.4, y = 0.85 , legend = c("Shelf 1", "Shelf 2", "Shelf 3", "Shelf 4"), col=c("blue","gray","red","green"),lty = "solid")

```

Jessica's solution:

```{r}
## Open question: in figure 3.3, they have each line stop at the min/max for each type of kernel (equivalent to each shelf in our example). Is this what we want, or do we want it to go from 0 to 1 for each shelf? (code for both below, 0-1 is commented out.)


beta.hat<-coefficients(mod1)
beta.hat
mean_fat <- mean(cereal2$fat)
mean_sodium <- mean(cereal2$sodium)


# Create plotting area first to make sure get the whole region with respect to x-axis
curve(expr = 1/(1 + exp(beta.hat[1,1] + beta.hat[1,2]*x) + exp(beta.hat[2,1] + beta.hat[2,2]*x)), ylab = expression(hat(pi)), xlab = "sugar",
  xlim = c(min(cereal2$sugar), max(cereal2$sugar)), ylim = c(0, 1), col = "black", lty = "solid", lwd = 2, n = 1000, type = "n",
  panel.first = grid(col = "gray", lty = "dotted"))

## Plot each pi_j
# Shelf1
curve(expr = 1/(1 + exp(beta.hat[1,1] + beta.hat[1,2]*x + beta.hat[1,3]*mean_fat + beta.hat[1,4]*mean_sodium)
                + exp(beta.hat[2,1] + beta.hat[2,2]*x + beta.hat[2,3]*mean_fat + beta.hat[2,4]*mean_sodium)
                + exp(beta.hat[3,1] + beta.hat[3,2]*x + beta.hat[3,3]*mean_fat + beta.hat[3,4]*mean_sodium)),
  col = "black", lty = "solid", lwd = 2, n = 1000, add = TRUE,
  xlim = c(min(cereal2$sugar[cereal2$Shelf == 1]), max(cereal2$sugar[cereal2$Shelf == 1])))
  # xlim = c(0,1))  

# Shelf2
curve(expr = exp(beta.hat[1,1] + beta.hat[1,2]*x + beta.hat[1,3]*mean_fat + beta.hat[1,4]*mean_sodium)/
        (1 + exp(beta.hat[1,1] + beta.hat[1,2]*x + beta.hat[1,3]*mean_fat + beta.hat[1,4]*mean_sodium)
                + exp(beta.hat[2,1] + beta.hat[2,2]*x + beta.hat[2,3]*mean_fat + beta.hat[2,4]*mean_sodium)
                + exp(beta.hat[3,1] + beta.hat[3,2]*x + beta.hat[3,3]*mean_fat + beta.hat[3,4]*mean_sodium)), 
      col = "green", lty = "longdash", lwd = 2, n = 1000, add = TRUE, 
      xlim = c(min(cereal2$sugar[cereal2$Shelf == 2]), max(cereal2$sugar[cereal2$Shelf == 2])))
      # xlim = c(0,1))  

# Shelf3
curve(expr = exp(beta.hat[2,1] + beta.hat[2,2]*x + beta.hat[2,3]*mean_fat + beta.hat[2,4]*mean_sodium)/
        (1 + exp(beta.hat[1,1] + beta.hat[1,2]*x + beta.hat[1,3]*mean_fat + beta.hat[1,4]*mean_sodium)
                + exp(beta.hat[2,1] + beta.hat[2,2]*x + beta.hat[2,3]*mean_fat + beta.hat[2,4]*mean_sodium)
                + exp(beta.hat[3,1] + beta.hat[3,2]*x + beta.hat[3,3]*mean_fat + beta.hat[3,4]*mean_sodium)),
  col = "red", lty = "dotdash", lwd = 2, n = 1000, add = TRUE,
  xlim = c(min(cereal2$sugar[cereal2$Shelf == 3]), max(cereal2$sugar[cereal2$Shelf == 3])))
  # xlim = c(0,1))

# Shelf4
curve(expr = exp(beta.hat[3,1] + beta.hat[3,2]*x + beta.hat[3,3]*mean_fat + beta.hat[3,4]*mean_sodium)/
        (1 + exp(beta.hat[1,1] + beta.hat[1,2]*x + beta.hat[1,3]*mean_fat + beta.hat[1,4]*mean_sodium)
                + exp(beta.hat[2,1] + beta.hat[2,2]*x + beta.hat[2,3]*mean_fat + beta.hat[2,4]*mean_sodium)
                + exp(beta.hat[3,1] + beta.hat[3,2]*x + beta.hat[3,3]*mean_fat + beta.hat[3,4]*mean_sodium)),
  col = "blue", lty = "dotted", lwd = 2, n = 1000, add = TRUE,
  xlim = c(min(cereal2$sugar[cereal2$Shelf == 4]), max(cereal2$sugar[cereal2$Shelf == 4])))   
  # xlim = c(0,1))




legend(x = 0.5, y = 1.0, legend=c("Shelf 1", "Shelf 2", "Shelf 3", "Shelf 4"), 
       lty=c("solid","longdash", "dotdash", "dotted"),
  col=c("black","green","red", "blue"), bty="n", lwd = c(2,2,2), seg.len = 4)


```

This chart shows the predicted probabilities of which shelf a box of cereal would be found on when sugar content is the only explanatory variable included in the model.

*Additional notes: In particular, the plot shows that for relatively low sugar levels, assuming average levels of fat and sodium, that shelf 3 or shelf 4 are vastly more likely, while for higher sugar content, shelf 2 becomes dominant in likelihood while shelf 1 becomes more likely than the remaining two shelves. This corresponds with the hypothesis that sugary cereals target children, who are closest to Shelves 1 & 2, but for whom shelves 3 & 4 are too difficult to either see or reach. It is also notable that the increase in likelihood for shelf 1 is clear but substantially subdued which can almost certainly be attributed to the assumption of average sodium levels, given that this is the key explanatory variable for shelf 1. 

***Key to-do: Merge solid and dotted line graphs for min-max ranges vs out of sample values respectively.

##(h) Estimate odds ratios and calculate corresponding confidence intervals for each explanatory variable. Relate your interpretations back to the plots constructed for this exercise.

```{r}
sd.cereal<-apply(X=cereal2[, -c(2)], MARGIN = 2, FUN = sd)
c.value<-c(sd.cereal)[2:4]
# Estimated standard deviations for each explanatory variable
round(c.value,2)

conf.beta <- confint(object = mod1, level = 0.95)
ci.OR <- exp(c.value*conf.beta[2:4,1:2,])

#coefficients(mod1)
beta.hat2<-coefficients(mod1)[1,2:4]
beta.hat3<-coefficients(mod1)[2,2:4]
beta.hat4<-coefficients(mod1)[3,2:4]

# OR for j = 2 (Shelf 2 vs Shelf 1)
print("OR for j = 2 vs j = 1")
mid2 = exp(c.value*beta.hat2)
round(mid2,2)
round(1/mid2,2)
round(data.frame(low = ci.OR[,1,1], mid = mid2, up = ci.OR[,2,1]),2)

# OR for j = 3 (Shelf 3 vs Shelf 1)
print("OR for j = 3 vs j = 1")
mid3 = exp(c.value*beta.hat3)
round(mid3,2)
round(1/mid3,2)
round(data.frame(low = ci.OR[,1,2], mid = mid3, up = ci.OR[,2,2]),2)

# OR for j = 4 (Shelf 4 vs Shelf 1)
print("OR for j = 3 vs j = 1")
mid4 = exp(c.value*beta.hat4)
round(mid4,2)
round(1/mid4,2)
round(data.frame(low = ci.OR[,1,3], mid = mid4, up = ci.OR[,2,3]),2)

# OR for j = 3 (Shelf 3 vs Shelf 2)
print("OR for j = 3 vs j = 2")
mid = exp(c.value*beta.hat3-c.value*beta.hat2)
round(mid,2)
round(1/mid,2)
low = apply(matrix(c(ci.OR[,1,2]/mid2,mid3/ci.OR[,2,1]),3),1,min)
up = apply(matrix(c(ci.OR[,2,2]/mid2,mid3/ci.OR[,1,1]),3),1,max)
round(data.frame(low = low, mid = mid, up = up),2)

# OR for j = 4 (Shelf 3 vs Shelf 2)
print("OR for j = 4 vs j = 2")
mid = exp(c.value*beta.hat4-c.value*beta.hat2)
round(mid,2)
round(1/mid,2)
low = apply(matrix(c(ci.OR[,1,3]/mid2,mid4/ci.OR[,2,1]),3),1,min)
up = apply(matrix(c(ci.OR[,2,3]/mid2,mid4/ci.OR[,1,1]),3),1,max)
round(data.frame(low = low, mid = mid, up = up),2)

# OR for j = 4 (Shelf 3 vs Shelf 3)
print("OR for j = 4 vs j = 3")
mid = exp(c.value*beta.hat4-c.value*beta.hat3)
round(mid,2)
round(1/mid,2)
low = apply(matrix(c(ci.OR[,1,3]/mid3,mid4/ci.OR[,2,2]),3),1,min)
up = apply(matrix(c(ci.OR[,2,3]/mid3,mid4/ci.OR[,1,2]),3),1,max)
round(data.frame(low = low, mid = mid, up = up),2)
```

*Key to-do: Add Confidence interval tables for each explanatory variable for each pair of shelves. Compare to plots above and in EDA. Refer to pages 160-163 in the book for guidance
